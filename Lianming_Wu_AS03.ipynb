{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_iris # I found that sklearn have iris dataset built in\n",
    "from sklearn.preprocessing import scale\n",
    "import numpy as np \n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.90068117  1.01900435]\n",
      " [-1.14301691 -0.13197948]\n",
      " [-1.38535265  0.32841405]\n",
      " [-1.50652052  0.09821729]\n",
      " [-1.02184904  1.24920112]\n",
      " [-0.53717756  1.93979142]\n",
      " [-1.50652052  0.78880759]\n",
      " [-1.02184904  0.78880759]\n",
      " [-1.74885626 -0.36217625]\n",
      " [-1.14301691  0.09821729]\n",
      " [-0.53717756  1.47939788]\n",
      " [-1.26418478  0.78880759]\n",
      " [-1.26418478 -0.13197948]\n",
      " [-1.87002413 -0.13197948]\n",
      " [-0.05250608  2.16998818]\n",
      " [-0.17367395  3.09077525]\n",
      " [-0.53717756  1.93979142]\n",
      " [-0.90068117  1.01900435]\n",
      " [-0.17367395  1.70959465]\n",
      " [-0.90068117  1.70959465]\n",
      " [-0.53717756  0.78880759]\n",
      " [-0.90068117  1.47939788]\n",
      " [-1.50652052  1.24920112]\n",
      " [-0.90068117  0.55861082]\n",
      " [-1.26418478  0.78880759]\n",
      " [-1.02184904 -0.13197948]\n",
      " [-1.02184904  0.78880759]\n",
      " [-0.7795133   1.01900435]\n",
      " [-0.7795133   0.78880759]\n",
      " [-1.38535265  0.32841405]\n",
      " [-1.26418478  0.09821729]\n",
      " [-0.53717756  0.78880759]\n",
      " [-0.7795133   2.40018495]\n",
      " [-0.41600969  2.63038172]\n",
      " [-1.14301691  0.09821729]\n",
      " [-1.02184904  0.32841405]\n",
      " [-0.41600969  1.01900435]\n",
      " [-1.14301691  1.24920112]\n",
      " [-1.74885626 -0.13197948]\n",
      " [-0.90068117  0.78880759]\n",
      " [-1.02184904  1.01900435]\n",
      " [-1.62768839 -1.74335684]\n",
      " [-1.74885626  0.32841405]\n",
      " [-1.02184904  1.01900435]\n",
      " [-0.90068117  1.70959465]\n",
      " [-1.26418478 -0.13197948]\n",
      " [-0.90068117  1.70959465]\n",
      " [-1.50652052  0.32841405]\n",
      " [-0.65834543  1.47939788]\n",
      " [-1.02184904  0.55861082]\n",
      " [ 1.40150837  0.32841405]\n",
      " [ 0.67450115  0.32841405]\n",
      " [ 1.2803405   0.09821729]\n",
      " [-0.41600969 -1.74335684]\n",
      " [ 0.79566902 -0.59237301]\n",
      " [-0.17367395 -0.59237301]\n",
      " [ 0.55333328  0.55861082]\n",
      " [-1.14301691 -1.51316008]\n",
      " [ 0.91683689 -0.36217625]\n",
      " [-0.7795133  -0.82256978]\n",
      " [-1.02184904 -2.43394714]\n",
      " [ 0.06866179 -0.13197948]\n",
      " [ 0.18982966 -1.97355361]\n",
      " [ 0.31099753 -0.36217625]\n",
      " [-0.29484182 -0.36217625]\n",
      " [ 1.03800476  0.09821729]\n",
      " [-0.29484182 -0.13197948]\n",
      " [-0.05250608 -0.82256978]\n",
      " [ 0.4321654  -1.97355361]\n",
      " [-0.29484182 -1.28296331]\n",
      " [ 0.06866179  0.32841405]\n",
      " [ 0.31099753 -0.59237301]\n",
      " [ 0.55333328 -1.28296331]\n",
      " [ 0.31099753 -0.59237301]\n",
      " [ 0.67450115 -0.36217625]\n",
      " [ 0.91683689 -0.13197948]\n",
      " [ 1.15917263 -0.59237301]\n",
      " [ 1.03800476 -0.13197948]\n",
      " [ 0.18982966 -0.36217625]\n",
      " [-0.17367395 -1.05276654]\n",
      " [-0.41600969 -1.51316008]\n",
      " [-0.41600969 -1.51316008]\n",
      " [-0.05250608 -0.82256978]\n",
      " [ 0.18982966 -0.82256978]\n",
      " [-0.53717756 -0.13197948]\n",
      " [ 0.18982966  0.78880759]\n",
      " [ 1.03800476  0.09821729]\n",
      " [ 0.55333328 -1.74335684]\n",
      " [-0.29484182 -0.13197948]\n",
      " [-0.41600969 -1.28296331]\n",
      " [-0.41600969 -1.05276654]\n",
      " [ 0.31099753 -0.13197948]\n",
      " [-0.05250608 -1.05276654]\n",
      " [-1.02184904 -1.74335684]\n",
      " [-0.29484182 -0.82256978]\n",
      " [-0.17367395 -0.13197948]\n",
      " [-0.17367395 -0.36217625]\n",
      " [ 0.4321654  -0.36217625]\n",
      " [-0.90068117 -1.28296331]\n",
      " [-0.17367395 -0.59237301]\n",
      " [ 0.55333328  0.55861082]\n",
      " [-0.05250608 -0.82256978]\n",
      " [ 1.52267624 -0.13197948]\n",
      " [ 0.55333328 -0.36217625]\n",
      " [ 0.79566902 -0.13197948]\n",
      " [ 2.12851559 -0.13197948]\n",
      " [-1.14301691 -1.28296331]\n",
      " [ 1.76501198 -0.36217625]\n",
      " [ 1.03800476 -1.28296331]\n",
      " [ 1.64384411  1.24920112]\n",
      " [ 0.79566902  0.32841405]\n",
      " [ 0.67450115 -0.82256978]\n",
      " [ 1.15917263 -0.13197948]\n",
      " [-0.17367395 -1.28296331]\n",
      " [-0.05250608 -0.59237301]\n",
      " [ 0.67450115  0.32841405]\n",
      " [ 0.79566902 -0.13197948]\n",
      " [ 2.24968346  1.70959465]\n",
      " [ 2.24968346 -1.05276654]\n",
      " [ 0.18982966 -1.97355361]\n",
      " [ 1.2803405   0.32841405]\n",
      " [-0.29484182 -0.59237301]\n",
      " [ 2.24968346 -0.59237301]\n",
      " [ 0.55333328 -0.82256978]\n",
      " [ 1.03800476  0.55861082]\n",
      " [ 1.64384411  0.32841405]\n",
      " [ 0.4321654  -0.59237301]\n",
      " [ 0.31099753 -0.13197948]\n",
      " [ 0.67450115 -0.59237301]\n",
      " [ 1.64384411 -0.13197948]\n",
      " [ 1.88617985 -0.59237301]\n",
      " [ 2.4920192   1.70959465]\n",
      " [ 0.67450115 -0.59237301]\n",
      " [ 0.55333328 -0.59237301]\n",
      " [ 0.31099753 -1.05276654]\n",
      " [ 2.24968346 -0.13197948]\n",
      " [ 0.55333328  0.78880759]\n",
      " [ 0.67450115  0.09821729]\n",
      " [ 0.18982966 -0.13197948]\n",
      " [ 1.2803405   0.09821729]\n",
      " [ 1.03800476  0.09821729]\n",
      " [ 1.2803405   0.09821729]\n",
      " [-0.05250608 -0.82256978]\n",
      " [ 1.15917263  0.32841405]\n",
      " [ 1.03800476  0.55861082]\n",
      " [ 1.03800476 -0.13197948]\n",
      " [ 0.55333328 -1.28296331]\n",
      " [ 0.79566902 -0.13197948]\n",
      " [ 0.4321654   0.78880759]\n",
      " [ 0.06866179 -0.13197948]]\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1]\n",
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n"
     ]
    }
   ],
   "source": [
    "iris = load_iris() # loads the iris dataset,its already being sorted in the form that can be easily processed by sklearn function\n",
    "X = scale(iris.data[:,:2])\n",
    "# It is indeed the dataset we want to look for\n",
    "print(X)\n",
    "Y = iris.target[:]\n",
    "# for convienience, I would represent setosa as -1, versicolor as 0, virinica as 1\n",
    "for i in range(50):\n",
    "    Y[i] = -1\n",
    "    Y[i+50] = 0\n",
    "    Y[i+100] = 1\n",
    "print(Y)\n",
    "\n",
    "# Some code trying to manipulate the data [:,:2] returns the first two features in the data, where (x,y) can access them at same time.\n",
    "#for (x,y)in X[:,:2]:\n",
    "#    print(x,y)\n",
    "# Get first and 3rd column\n",
    "#iris.data[:100,(1,3)]\n",
    "print(iris.feature_names[:])\n",
    "#print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Based on the slides on class, the default parameter for the scikit learn LogisticRegression are \n",
    "Penalty:l2, Max_iter = 100, and solver = liblinear. According to the documentation, liblinear is good for \n",
    "small dataset. However, it can only handle binary classify and we have 3 classes, I would choose saga instead, as it \n",
    "supports muticlass classify can also accept l1 penalty.\n",
    "\n",
    "I would use score function for comparing the accurary.\n",
    "According to the documentation, to use the saga model, we need to scale our data, so I used the preprocessing tool\n",
    "in sklearn to scale our data.\n",
    "Because for some choice of feature, Max_iter is reached pretty quicly, I changed max_iter to 500\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "For each of the cases, I would test the following cases.\n",
    "1. Use saga and mutinomial model, all other to default.\n",
    "2. Change C to 0.5\n",
    "3. Change C to 0.25\n",
    "4. Change C to 1.5\n",
    "5. Change C to 3\n",
    "6. Change to l1 regularization\n",
    "7. l1 with C = 0.5\n",
    "8. l1 with C = 0.25\n",
    "9. l1 with C = 1.5\n",
    "10. l1 with C = 3\n",
    "\"\"\"\n",
    "\n",
    "def log_reg(X,Y):\n",
    "    result = []\n",
    "    #1. L2, other default\n",
    "    LogReg = LogisticRegression(solver = 'saga',multi_class='multinomial',verbose=1,max_iter = 500).fit(X,Y)\n",
    "    score = round(LogReg.score(X,Y),3)\n",
    "    print(\"L2,other default. Score: {}\".format(score))\n",
    "    result.append(score)\n",
    "    result.append(LogReg.n_iter_)\n",
    "    #2. C = 0.5\n",
    "    LogReg = LogisticRegression(solver = 'saga',multi_class='multinomial',C=0.5,verbose=1,max_iter = 500).fit(X,Y)\n",
    "    score = round(LogReg.score(X,Y),3)\n",
    "    print(\"L2,C = 0.5. Score: {}\".format(score))\n",
    "    result.append(score)\n",
    "    result.append(LogReg.n_iter_)\n",
    "    #3. C = 0.25\n",
    "    LogReg = LogisticRegression(solver = 'saga',multi_class='multinomial',C=0.25,verbose=1,max_iter = 500).fit(X,Y)\n",
    "    score = round(LogReg.score(X,Y),3)\n",
    "    print(\"L2,C = 0.25. Score: {}\".format(score))\n",
    "    result.append(score)\n",
    "    result.append(LogReg.n_iter_)\n",
    "    #4 C = 1.5\n",
    "    LogReg = LogisticRegression(solver = 'saga',multi_class='multinomial',C=1.5,verbose=1,max_iter = 500).fit(X,Y)\n",
    "    score = round(LogReg.score(X,Y),3)\n",
    "    print(\"L2,C = 1.5. Score: {}\".format(score))\n",
    "    result.append(score)\n",
    "    result.append(LogReg.n_iter_)\n",
    "     #5 C = 3\n",
    "    LogReg = LogisticRegression(solver = 'saga',multi_class='multinomial',C=3,verbose=1,max_iter = 500).fit(X,Y)\n",
    "    score = round(LogReg.score(X,Y),3)\n",
    "    print(\"L2,C = 3. Score: {}\".format(score))\n",
    "    result.append(score)\n",
    "    result.append(LogReg.n_iter_)\n",
    "    #6. l1 regularization, other default\n",
    "    LogReg = LogisticRegression(solver = 'saga',multi_class='multinomial',penalty = 'l1',verbose=1,max_iter = 500).fit(X,Y)\n",
    "    score = round(LogReg.score(X,Y),3)\n",
    "    print(\"L1,other default. Score: {}\".format(score))\n",
    "    result.append(score)\n",
    "    result.append(LogReg.n_iter_)\n",
    "    #7. l1, C = 0.5\n",
    "    LogReg = LogisticRegression(solver = 'saga',multi_class='multinomial',C=0.5,penalty = 'l1',verbose=1,max_iter = 500).fit(X,Y)\n",
    "    score = round(LogReg.score(X,Y),3)\n",
    "    print(\"L1,C = 0.5. Score: {}\".format(score))\n",
    "    result.append(score)\n",
    "    result.append(LogReg.n_iter_)\n",
    "    #8 l1, C = 0.25\n",
    "    LogReg = LogisticRegression(solver = 'saga',multi_class='multinomial',C=0.25,penalty = 'l1',verbose=1,max_iter = 500).fit(X,Y)\n",
    "    score = round(LogReg.score(X,Y),3)\n",
    "    print(\"L1,C = 0.25. Score: {}\".format(score))\n",
    "    result.append(score)\n",
    "    result.append(LogReg.n_iter_)\n",
    "    #9 l1, C = 1.5\n",
    "    LogReg = LogisticRegression(solver = 'saga',multi_class='multinomial',C=1.5,penalty = 'l1',verbose=1,max_iter = 500).fit(X,Y)\n",
    "    score = round(LogReg.score(X,Y),3)\n",
    "    print(\"L1,C = 1.5. Score: {}\".format(score))\n",
    "    result.append(score)\n",
    "    result.append(LogReg.n_iter_)\n",
    "     #10 l1, C = 1.5\n",
    "    LogReg = LogisticRegression(solver = 'saga',multi_class='multinomial',C=3,penalty = 'l1',verbose=1,max_iter = 500).fit(X,Y)\n",
    "    score = round(LogReg.score(X,Y),3)\n",
    "    print(\"L1,C = 3. Score: {}\".format(score))\n",
    "    result.append(score)\n",
    "    result.append(LogReg.n_iter_)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 17 epochs took 0 seconds\n",
      "L2,other default. Score: 0.813\n",
      "convergence after 15 epochs took 0 seconds\n",
      "L2,C = 0.5. Score: 0.813\n",
      "convergence after 15 epochs took 0 seconds\n",
      "L2,C = 0.25. Score: 0.807\n",
      "convergence after 25 epochs took 0 seconds\n",
      "L2,C = 1.5. Score: 0.82\n",
      "convergence after 35 epochs took 0 seconds\n",
      "L2,C = 3. Score: 0.82\n",
      "convergence after 45 epochs took 0 seconds\n",
      "L1,other default. Score: 0.833\n",
      "convergence after 29 epochs took 0 seconds\n",
      "L1,C = 0.5. Score: 0.82\n",
      "convergence after 18 epochs took 0 seconds\n",
      "L1,C = 0.25. Score: 0.813\n",
      "convergence after 71 epochs took 0 seconds\n",
      "L1,C = 1.5. Score: 0.833\n",
      "convergence after 158 epochs took 0 seconds\n",
      "L1,C = 3. Score: 0.833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "# Case 1: Use sepal length and sepal width\n",
    "SSW_data = log_reg(X,Y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 29 epochs took 0 seconds\n",
      "L2,other default. Score: 0.953\n",
      "convergence after 17 epochs took 0 seconds\n",
      "L2,C = 0.5. Score: 0.933\n",
      "convergence after 14 epochs took 0 seconds\n",
      "L2,C = 0.25. Score: 0.887\n",
      "convergence after 34 epochs took 0 seconds\n",
      "L2,C = 1.5. Score: 0.96\n",
      "convergence after 48 epochs took 0 seconds\n",
      "L2,C = 3. Score: 0.96\n",
      "convergence after 73 epochs took 0 seconds\n",
      "L1,other default. Score: 0.96\n",
      "convergence after 42 epochs took 0 seconds\n",
      "L1,C = 0.5. Score: 0.96\n",
      "convergence after 19 epochs took 0 seconds\n",
      "L1,C = 0.25. Score: 0.953\n",
      "convergence after 111 epochs took 0 seconds\n",
      "L1,C = 1.5. Score: 0.953\n",
      "convergence after 174 epochs took 0 seconds\n",
      "L1,C = 3. Score: 0.953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "#Case2: Sepal length and Pedal length\n",
    "X = scale(iris.data[:,:])\n",
    "SP = X[:,(0,2)]\n",
    "SP_data = log_reg(SP,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 22 epochs took 0 seconds\n",
      "L2,other default. Score: 0.96\n",
      "convergence after 16 epochs took 0 seconds\n",
      "L2,C = 0.5. Score: 0.96\n",
      "convergence after 14 epochs took 0 seconds\n",
      "L2,C = 0.25. Score: 0.947\n",
      "convergence after 23 epochs took 0 seconds\n",
      "L2,C = 1.5. Score: 0.96\n",
      "convergence after 33 epochs took 0 seconds\n",
      "L2,C = 3. Score: 0.96\n",
      "convergence after 33 epochs took 0 seconds\n",
      "L1,other default. Score: 0.96\n",
      "convergence after 19 epochs took 0 seconds\n",
      "L1,C = 0.5. Score: 0.96\n",
      "convergence after 18 epochs took 0 seconds\n",
      "L1,C = 0.25. Score: 0.96\n",
      "convergence after 55 epochs took 0 seconds\n",
      "L1,C = 1.5. Score: 0.96\n",
      "convergence after 90 epochs took 0 seconds\n",
      "L1,C = 3. Score: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "# Case 3, Sepal length, Pedal Width\n",
    "SPW = X[:,(0,3)]\n",
    "SPW_data = log_reg(SPW,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 30 epochs took 0 seconds\n",
      "L2,other default. Score: 0.953\n",
      "convergence after 20 epochs took 0 seconds\n",
      "L2,C = 0.5. Score: 0.92\n",
      "convergence after 14 epochs took 0 seconds\n",
      "L2,C = 0.25. Score: 0.9\n",
      "convergence after 37 epochs took 0 seconds\n",
      "L2,C = 1.5. Score: 0.953\n",
      "convergence after 53 epochs took 0 seconds\n",
      "L2,C = 3. Score: 0.96\n",
      "convergence after 85 epochs took 0 seconds\n",
      "L1,other default. Score: 0.96\n",
      "convergence after 48 epochs took 0 seconds\n",
      "L1,C = 0.5. Score: 0.953\n",
      "convergence after 21 epochs took 0 seconds\n",
      "L1,C = 0.25. Score: 0.953\n",
      "convergence after 115 epochs took 0 seconds\n",
      "L1,C = 1.5. Score: 0.96\n",
      "convergence after 167 epochs took 0 seconds\n",
      "L1,C = 3. Score: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "# Case 4, Sepal width, pedal length\n",
    "SWP = X[:,(1,2)]\n",
    "SWP_data = log_reg(SWP,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 25 epochs took 0 seconds\n",
      "L2,other default. Score: 0.953\n",
      "convergence after 16 epochs took 0 seconds\n",
      "L2,C = 0.5. Score: 0.953\n",
      "convergence after 15 epochs took 0 seconds\n",
      "L2,C = 0.25. Score: 0.933\n",
      "convergence after 31 epochs took 0 seconds\n",
      "L2,C = 1.5. Score: 0.953\n",
      "convergence after 43 epochs took 0 seconds\n",
      "L2,C = 3. Score: 0.96\n",
      "convergence after 51 epochs took 0 seconds\n",
      "L1,other default. Score: 0.96\n",
      "convergence after 36 epochs took 0 seconds\n",
      "L1,C = 0.5. Score: 0.96\n",
      "convergence after 25 epochs took 0 seconds\n",
      "L1,C = 0.25. Score: 0.96\n",
      "convergence after 69 epochs took 0 seconds\n",
      "L1,C = 1.5. Score: 0.96\n",
      "convergence after 93 epochs took 0 seconds\n",
      "L1,C = 3. Score: 0.953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "# Case 5, Sepal width, pedal width\n",
    "SWPW = X[:,(1,3)]\n",
    "SWPW_data = log_reg(SWPW,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 18 epochs took 0 seconds\n",
      "L2,other default. Score: 0.953\n",
      "convergence after 14 epochs took 0 seconds\n",
      "L2,C = 0.5. Score: 0.96\n",
      "convergence after 13 epochs took 0 seconds\n",
      "L2,C = 0.25. Score: 0.953\n",
      "convergence after 29 epochs took 0 seconds\n",
      "L2,C = 1.5. Score: 0.953\n",
      "convergence after 35 epochs took 0 seconds\n",
      "L2,C = 3. Score: 0.96\n",
      "convergence after 376 epochs took 0 seconds\n",
      "L1,other default. Score: 0.96\n",
      "convergence after 101 epochs took 0 seconds\n",
      "L1,C = 0.5. Score: 0.953\n",
      "convergence after 37 epochs took 0 seconds\n",
      "L1,C = 0.25. Score: 0.96\n",
      "convergence after 461 epochs took 0 seconds\n",
      "L1,C = 1.5. Score: 0.96\n",
      "max_iter reached after 0 seconds\n",
      "L1,C = 3. Score: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\Users\\lianm\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "# Case 6, Pedal length, Pedal Width\n",
    "PPW = X[:,(2,3)]\n",
    "PPW_data = log_reg(PPW,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 39 epochs took 0 seconds\n",
      "L2,other default. Score: 0.967\n",
      "convergence after 25 epochs took 0 seconds\n",
      "L2,C = 0.5. Score: 0.933\n",
      "convergence after 16 epochs took 0 seconds\n",
      "L2,C = 0.25. Score: 0.893\n",
      "convergence after 41 epochs took 0 seconds\n",
      "L2,C = 1.5. Score: 0.96\n",
      "convergence after 70 epochs took 0 seconds\n",
      "L2,C = 3. Score: 0.96\n",
      "convergence after 101 epochs took 0 seconds\n",
      "L1,other default. Score: 0.96\n",
      "convergence after 53 epochs took 0 seconds\n",
      "L1,C = 0.5. Score: 0.96\n",
      "convergence after 21 epochs took 0 seconds\n",
      "L1,C = 0.25. Score: 0.953\n",
      "convergence after 145 epochs took 1 seconds\n",
      "L1,C = 1.5. Score: 0.96\n",
      "convergence after 249 epochs took 0 seconds\n",
      "L1,C = 3. Score: 0.973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "# Case 7 Sepal length, sepal width, pedal length\n",
    "SSWP = X[:,(0,1,2)]\n",
    "SSWP_data = log_reg(SSWP,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 32 epochs took 0 seconds\n",
      "L2,other default. Score: 0.96\n",
      "convergence after 22 epochs took 0 seconds\n",
      "L2,C = 0.5. Score: 0.96\n",
      "convergence after 14 epochs took 0 seconds\n",
      "L2,C = 0.25. Score: 0.947\n",
      "convergence after 40 epochs took 0 seconds\n",
      "L2,C = 1.5. Score: 0.96\n",
      "convergence after 60 epochs took 0 seconds\n",
      "L2,C = 3. Score: 0.967\n",
      "convergence after 108 epochs took 0 seconds\n",
      "L1,other default. Score: 0.96\n",
      "convergence after 49 epochs took 0 seconds\n",
      "L1,C = 0.5. Score: 0.96\n",
      "convergence after 28 epochs took 0 seconds\n",
      "L1,C = 0.25. Score: 0.96\n",
      "convergence after 185 epochs took 0 seconds\n",
      "L1,C = 1.5. Score: 0.96\n",
      "convergence after 407 epochs took 0 seconds\n",
      "L1,C = 3. Score: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "# Case 8 Sepal length, sepal width, pedal width\n",
    "SSWPW = X[:,(0,1,3)]\n",
    "SSWPW_data = log_reg(SSWPW,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\Users\\lianm\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\Users\\lianm\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 38 epochs took 0 seconds\n",
      "L2,other default. Score: 0.953\n",
      "convergence after 23 epochs took 0 seconds\n",
      "L2,C = 0.5. Score: 0.96\n",
      "convergence after 14 epochs took 0 seconds\n",
      "L2,C = 0.25. Score: 0.96\n",
      "convergence after 44 epochs took 0 seconds\n",
      "L2,C = 1.5. Score: 0.96\n",
      "convergence after 67 epochs took 0 seconds\n",
      "L2,C = 3. Score: 0.967\n",
      "max_iter reached after 0 seconds\n",
      "L1,other default. Score: 0.96\n",
      "convergence after 171 epochs took 0 seconds\n",
      "L1,C = 0.5. Score: 0.953\n",
      "convergence after 59 epochs took 0 seconds\n",
      "L1,C = 0.25. Score: 0.96\n",
      "max_iter reached after 0 seconds\n",
      "L1,C = 1.5. Score: 0.967\n",
      "max_iter reached after 0 seconds\n",
      "L1,C = 3. Score: 0.967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lianm\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "# Case 9 Sepal length, pedal length, pedal width\n",
    "SPPW = X[:,(0,2,3)]\n",
    "SPPW_data = log_reg(SPPW,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\Users\\lianm\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\Users\\lianm\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 36 epochs took 0 seconds\n",
      "L2,other default. Score: 0.973\n",
      "convergence after 29 epochs took 0 seconds\n",
      "L2,C = 0.5. Score: 0.953\n",
      "convergence after 18 epochs took 0 seconds\n",
      "L2,C = 0.25. Score: 0.96\n",
      "convergence after 48 epochs took 0 seconds\n",
      "L2,C = 1.5. Score: 0.973\n",
      "convergence after 68 epochs took 0 seconds\n",
      "L2,C = 3. Score: 0.973\n",
      "max_iter reached after 0 seconds\n",
      "L1,other default. Score: 0.973\n",
      "convergence after 156 epochs took 0 seconds\n",
      "L1,C = 0.5. Score: 0.953\n",
      "convergence after 61 epochs took 0 seconds\n",
      "L1,C = 0.25. Score: 0.96\n",
      "max_iter reached after 0 seconds\n",
      "L1,C = 1.5. Score: 0.973\n",
      "max_iter reached after 0 seconds\n",
      "L1,C = 3. Score: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lianm\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "# Case 10 Sepal width, pedal length, pedal width\n",
    "SWPPW = X[:,(1,2,3)]\n",
    "SWPPW_data = log_reg(SWPPW,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\Users\\lianm\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\Users\\lianm\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 45 epochs took 0 seconds\n",
      "L2,other default. Score: 0.973\n",
      "convergence after 29 epochs took 0 seconds\n",
      "L2,C = 0.5. Score: 0.953\n",
      "convergence after 15 epochs took 0 seconds\n",
      "L2,C = 0.25. Score: 0.96\n",
      "convergence after 58 epochs took 0 seconds\n",
      "L2,C = 1.5. Score: 0.973\n",
      "convergence after 86 epochs took 0 seconds\n",
      "L2,C = 3. Score: 0.973\n",
      "max_iter reached after 0 seconds\n",
      "L1,other default. Score: 0.973\n",
      "convergence after 164 epochs took 0 seconds\n",
      "L1,C = 0.5. Score: 0.953\n",
      "convergence after 65 epochs took 0 seconds\n",
      "L1,C = 0.25. Score: 0.96\n",
      "max_iter reached after 0 seconds\n",
      "L1,C = 1.5. Score: 0.973\n",
      "max_iter reached after 0 seconds\n",
      "L1,C = 3. Score: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lianm\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "# 11 all\n",
    "ALL_data = log_reg(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><td>Features Used</td><td>L2</td><td>L2,C=0.5</td><td>L2,C=0.25</td><td>L2,C=1.5</td><td>L2,C=3</td><td>L1</td><td>L1,C=0.5</td><td>L1,C=0.25</td><td>L1,C=1.5</td><td>L2,C=3</td></tr><tr><td>SSW</td><td>0.813</td><td>0.813</td><td>0.807</td><td>0.82</td><td>0.82</td><td>0.833</td><td>0.82</td><td>0.813</td><td>0.833</td><td>0.833</td></tr><tr><td>SP</td><td>0.953</td><td>0.933</td><td>0.887</td><td>0.96</td><td>0.96</td><td>0.96</td><td>0.96</td><td>0.953</td><td>0.953</td><td>0.953</td></tr><tr><td>SPW</td><td>0.96</td><td>0.96</td><td>0.947</td><td>0.96</td><td>0.96</td><td>0.96</td><td>0.96</td><td>0.96</td><td>0.96</td><td>0.96</td></tr><tr><td>SWP</td><td>0.953</td><td>0.92</td><td>0.9</td><td>0.953</td><td>0.96</td><td>0.96</td><td>0.953</td><td>0.953</td><td>0.96</td><td>0.96</td></tr><tr><td>SWPW</td><td>0.953</td><td>0.953</td><td>0.933</td><td>0.953</td><td>0.96</td><td>0.96</td><td>0.96</td><td>0.96</td><td>0.96</td><td>0.953</td></tr><tr><td>PPW</td><td>0.953</td><td>0.96</td><td>0.953</td><td>0.953</td><td>0.96</td><td>0.96</td><td>0.953</td><td>0.96</td><td>0.96</td><td>0.96</td></tr><tr><td>SSWP</td><td>0.967</td><td>0.933</td><td>0.893</td><td>0.96</td><td>0.96</td><td>0.96</td><td>0.96</td><td>0.953</td><td>0.96</td><td>0.973</td></tr><tr><td>SSWPW</td><td>0.96</td><td>0.96</td><td>0.947</td><td>0.96</td><td>0.967</td><td>0.96</td><td>0.96</td><td>0.96</td><td>0.96</td><td>0.96</td></tr><tr><td>SPPW</td><td>0.953</td><td>0.96</td><td>0.96</td><td>0.96</td><td>0.967</td><td>0.96</td><td>0.953</td><td>0.96</td><td>0.967</td><td>0.967</td></tr><tr><td>SWPPW</td><td>0.973</td><td>0.953</td><td>0.96</td><td>0.973</td><td>0.973</td><td>0.973</td><td>0.953</td><td>0.96</td><td>0.973</td><td>0.98</td></tr><tr><td>ALL</td><td>0.973</td><td>0.953</td><td>0.96</td><td>0.973</td><td>0.973</td><td>0.973</td><td>0.953</td><td>0.96</td><td>0.973</td><td>0.98</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'\\nThe table below shows mean accuracy of the  logistic regression model to reach convergence of \\nstop criteria <= 0.0001\\n'"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML, display\n",
    "data = [['Features Used','L2','L2,C=0.5','L2,C=0.25','L2,C=1.5','L2,C=3','L1','L1,C=0.5','L1,C=0.25','L1,C=1.5'\n",
    "        ,'L2,C=3'],\n",
    "        [\"SSW\"] + SSW_data[0::2],\n",
    "        [\"SP\"] + SP_data[0::2],\n",
    "        [\"SPW\"] + SPW_data[0::2],\n",
    "        [\"SWP\"] + SWP_data[0::2],\n",
    "        [\"SWPW\"] + SWPW_data[0::2],\n",
    "        [\"PPW\"] + PPW_data[0::2],\n",
    "        [\"SSWP\"] + SSWP_data[0::2],\n",
    "        [\"SSWPW\"] + SSWPW_data[0::2],\n",
    "        [\"SPPW\"] + SPPW_data[0::2],\n",
    "        [\"SWPPW\"] + SWPPW_data[0::2],\n",
    "        [\"ALL\"] + ALL_data[0::2],\n",
    "        ]\n",
    "# Code from Stack Overflow https://stackoverflow.com/questions/35160256/how-do-i-output-lists-as-a-table-in-jupyter-notebook\n",
    "display(HTML(\n",
    "   '<table><tr>{}</tr></table>'.format(\n",
    "       '</tr><tr>'.join(\n",
    "           '<td>{}</td>'.format('</td><td>'.join(str(_) for _ in row)) for row in data)\n",
    "       )\n",
    "))\n",
    "\n",
    "\"\"\"\n",
    "The table below shows mean accuracy of the  logistic regression model to reach convergence of \n",
    "stop criteria <= 0.0001\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><td>Features Used</td><td>L2</td><td>L2,C=0.5</td><td>L2,C=0.25</td><td>L2,C=1.5</td><td>L2,C=3</td><td>L1</td><td>L1,C=0.5</td><td>L1,C=0.25</td><td>L1,C=1.5</td><td>L2,C=3</td></tr><tr><td>SSW</td><td>[17]</td><td>[15]</td><td>[15]</td><td>[25]</td><td>[35]</td><td>[45]</td><td>[29]</td><td>[18]</td><td>[71]</td><td>[158]</td></tr><tr><td>SP</td><td>[29]</td><td>[17]</td><td>[14]</td><td>[34]</td><td>[48]</td><td>[73]</td><td>[42]</td><td>[19]</td><td>[111]</td><td>[174]</td></tr><tr><td>SPW</td><td>[22]</td><td>[16]</td><td>[14]</td><td>[23]</td><td>[33]</td><td>[33]</td><td>[19]</td><td>[18]</td><td>[55]</td><td>[90]</td></tr><tr><td>SWP</td><td>[30]</td><td>[20]</td><td>[14]</td><td>[37]</td><td>[53]</td><td>[85]</td><td>[48]</td><td>[21]</td><td>[115]</td><td>[167]</td></tr><tr><td>SWPW</td><td>[25]</td><td>[16]</td><td>[15]</td><td>[31]</td><td>[43]</td><td>[51]</td><td>[36]</td><td>[25]</td><td>[69]</td><td>[93]</td></tr><tr><td>PPW</td><td>[18]</td><td>[14]</td><td>[13]</td><td>[29]</td><td>[35]</td><td>[376]</td><td>[101]</td><td>[37]</td><td>[461]</td><td>[500]</td></tr><tr><td>SSWP</td><td>[39]</td><td>[25]</td><td>[16]</td><td>[41]</td><td>[70]</td><td>[101]</td><td>[53]</td><td>[21]</td><td>[145]</td><td>[249]</td></tr><tr><td>SSWPW</td><td>[32]</td><td>[22]</td><td>[14]</td><td>[40]</td><td>[60]</td><td>[108]</td><td>[49]</td><td>[28]</td><td>[185]</td><td>[407]</td></tr><tr><td>SPPW</td><td>[38]</td><td>[23]</td><td>[14]</td><td>[44]</td><td>[67]</td><td>[500]</td><td>[171]</td><td>[59]</td><td>[500]</td><td>[500]</td></tr><tr><td>SWPPW</td><td>[36]</td><td>[29]</td><td>[18]</td><td>[48]</td><td>[68]</td><td>[500]</td><td>[156]</td><td>[61]</td><td>[500]</td><td>[500]</td></tr><tr><td>ALL</td><td>[45]</td><td>[29]</td><td>[15]</td><td>[58]</td><td>[86]</td><td>[500]</td><td>[164]</td><td>[65]</td><td>[500]</td><td>[500]</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'\\nThe table below shows the number of iterations required for the logistic regression model to reach convergence of \\nstop criteria <= 0.0001\\n'"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [['Features Used','L2','L2,C=0.5','L2,C=0.25','L2,C=1.5','L2,C=3','L1','L1,C=0.5','L1,C=0.25','L1,C=1.5'\n",
    "        ,'L2,C=3'],\n",
    "        [\"SSW\"] + SSW_data[1::2],\n",
    "        [\"SP\"] + SP_data[1::2],\n",
    "        [\"SPW\"] + SPW_data[1::2],\n",
    "        [\"SWP\"] + SWP_data[1::2],\n",
    "        [\"SWPW\"] + SWPW_data[1::2],\n",
    "        [\"PPW\"] + PPW_data[1::2],\n",
    "        [\"SSWP\"] + SSWP_data[1::2],\n",
    "        [\"SSWPW\"] + SSWPW_data[1::2],\n",
    "        [\"SPPW\"] + SPPW_data[1::2],\n",
    "        [\"SWPPW\"] + SWPPW_data[1::2],\n",
    "        [\"ALL\"] + ALL_data[1::2],\n",
    "        ]\n",
    "# Code from Stack Overflow https://stackoverflow.com/questions/35160256/how-do-i-output-lists-as-a-table-in-jupyter-notebook\n",
    "display(HTML(\n",
    "   '<table><tr>{}</tr></table>'.format(\n",
    "       '</tr><tr>'.join(\n",
    "           '<td>{}</td>'.format('</td><td>'.join(str(_) for _ in row)) for row in data)\n",
    "       )\n",
    "))\n",
    "\n",
    "\"\"\"\n",
    "The table below shows the number of iterations required for the logistic regression model to reach convergence of \n",
    "stop criteria <= 0.0001\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nIn this training, other than the penalty, regularization strengh, all of other parameters are held the same for all of the \\ntesting cases to eliminate unstable factors for the result to be significant.\\n\\nBased on the result of the above tables, the following analysis are made\\n\\n1. Just like the Adaline model, the harder the result to be linearly seperated, the lower the accuracy. This is pretty intuiative.\\n(I drawn the SSW(sepal length, sepal width) scatter plot last time, it is clear that SSW is the most \"mixed\" case in all of the \\n6 cases using 2 features at a time)\\n\\n2. Logistic Regression model have an overall better accuracy than the Adaline model across the whole table. Improved from 0.73 to 0.833\\nfor the SSW, others all have a 2-5% improvement. Also the models converge much more quickly than the Adaline model with most of the \\ncases achieve a good accuracy within 100 iterations versus the Adaline using hundreds of iterations.\\n\\n3. Looks the lesser the features, the faster the convergence. Also, the smaller the C(means stronger regularization strength), the faster\\nthe convergence speed.\\n\\n4. Eventhough the small C improves the convergence speed, the accuracy of the model decreases with stronger regularization. In other hand\\nthe weaker the regularization strength, the better the accuracy, and the slower the convergence rate.\\n\\n5. More features used improves the accuracy overall, L1 regularization have a better accuracy than L2, but with slower convergence speed\\n(Looks like a trend, to have better accuracy, you need to sacrifice the convergence speed.)\\n\\n6. PPW(pedal width and length) have a suprising slow convergence speed when using L1 penalty even though it only uses 2 features at \\na time. It\\'s L2 regularization is as fast as other 2 features case, kind of weired. By analysising the scatter plot I don\\'t find any\\nspecial thing about it. However, when checking the convergence speed of it with Adaline model, I found that PPW also have a very \\nlow convergence speed with Adalines, it might be due to the fact that the gradient descent method works slow for this specific dataset.\\n'"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Now its the time to have discussion of the result I obtained by using Logistic Regression model to classify the iris_dataset.\n",
    "I would use the training result from the Adaline model to support my analysis.\n",
    "\n",
    "Note that because logistic regression need a certain amount of sample size for the result to be relevant, I used all of the dataset\n",
    "to train the model rather than splitting the dataset into testset and training set. Which is probably what I should have done in the \n",
    "Adaline model. With all that being said, like last time the following analysis are just based on the performance of the logistic model \n",
    "when the training set IS THE validation set, so I would not make any assumption of the model's performance to new data.\n",
    "\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "In this training, other than the penalty, regularization strengh, all of other parameters are held the same for all of the \n",
    "testing cases to eliminate unstable factors for the result to be significant.\n",
    "\n",
    "Based on the result of the above tables, the following analysis are made\n",
    "\n",
    "1. Just like the Adaline model, the harder the result to be linearly seperated, the lower the accuracy. This is pretty intuiative.\n",
    "(I drawn the SSW(sepal length, sepal width) scatter plot last time, it is clear that SSW is the most \"mixed\" case in all of the \n",
    "6 cases using 2 features at a time)\n",
    "\n",
    "2. Logistic Regression model have an overall better accuracy than the Adaline model across the whole table. Improved from 0.73 to 0.833\n",
    "for the SSW, others all have a 1-5% improvement. Also the models converge much more quickly than the Adaline model with most of the \n",
    "cases achieve a good accuracy within 100 iterations versus the Adaline using hundreds of iterations.\n",
    "\n",
    "3. Looks like the lesser the features, the faster the convergence. Also, the smaller the C(means stronger regularization strength), \n",
    "the faster the convergence speed.\n",
    "\n",
    "4. Even though the small C improves the convergence speed, the accuracy of the model decreases with stronger regularization. In other hand\n",
    "the weaker the regularization strength, the better the accuracy, and the slower the convergence rate.\n",
    "\n",
    "5. More features used improves the accuracy overall with slower convergence speed, L1 regularization have a better accuracy than L2, \n",
    "but with slower convergence speed as well(Looks like a trend, to have better accuracy, you need to sacrifice the convergence speed.)\n",
    "\n",
    "6. PPW(pedal width and length) have a suprising slow convergence speed when using L1 penalty even though it only uses 2 features at \n",
    "a time. It's L2 regularization is as fast as other 2 features case, kind of weired. By analysising the scatter plot I don't find any\n",
    "special thing about it. However, when checking the convergence speed of it with Adaline model, I found that PPW also have a very \n",
    "low convergence speed with Adalines, it might be due to the fact that the gradient descent method works slow for this specific dataset.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 18 epochs took 0 seconds\n",
      "L1,C = 0.05. Score: 0.94\n",
      "convergence after 628 epochs took 0 seconds\n",
      "L1,C = 5. Score: 0.98\n",
      "convergence after 16 epochs took 0 seconds\n",
      "L2,C = 0.05. Score: 0.907\n",
      "convergence after 121 epochs took 0 seconds\n",
      "L2,C = 5. Score: 0.98\n",
      "convergence after 15 epochs took 0 seconds\n",
      "L2,C = 0.001. Score: 0.88\n",
      "convergence after 376 epochs took 0 seconds\n",
      "L2,C = 50. Score: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "# Below, I verify my findings\n",
    "LogReg = LogisticRegression(solver = 'saga',multi_class='multinomial',C=0.05,penalty = 'l1',verbose=1,max_iter = 5000).fit(X,Y)\n",
    "score = round(LogReg.score(X,Y),3)\n",
    "print(\"L1,C = 0.05. Score: {}\".format(score))\n",
    "LogReg = LogisticRegression(solver = 'saga',multi_class='multinomial',C=5,penalty = 'l1',verbose=1,max_iter = 5000).fit(X,Y)\n",
    "score = round(LogReg.score(X,Y),3)\n",
    "print(\"L1,C = 5. Score: {}\".format(score))\n",
    "LogReg = LogisticRegression(solver = 'saga',multi_class='multinomial',C=0.05,verbose=1,max_iter = 5000).fit(X,Y)\n",
    "score = round(LogReg.score(X,Y),3)\n",
    "print(\"L2,C = 0.05. Score: {}\".format(score))\n",
    "LogReg = LogisticRegression(solver = 'saga',multi_class='multinomial',C=5,verbose=1,max_iter = 5000).fit(X,Y)\n",
    "score = round(LogReg.score(X,Y),3)\n",
    "print(\"L2,C = 5. Score: {}\".format(score))\n",
    "\n",
    "LogReg = LogisticRegression(solver = 'saga',multi_class='multinomial',C=0.01,verbose=1,max_iter = 5000).fit(X,Y)\n",
    "score = round(LogReg.score(X,Y),3)\n",
    "print(\"L2,C = 0.001. Score: {}\".format(score))\n",
    "\n",
    "LogReg = LogisticRegression(solver = 'saga',multi_class='multinomial',C=50,verbose=1,max_iter = 5000).fit(X,Y)\n",
    "score = round(LogReg.score(X,Y),3)\n",
    "print(\"L2,C = 50. Score: {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Looks like the analysis above is correct, stronger strength(lower the C) the faster the convergence, but worse the accuracy and vice\n",
    "versa. L1 penalty have a overall slower convergence speed and better accuracy.\n",
    "\n",
    "Overall, looks like logistic regression model performs better and run faster(might be the case that scikit learn's code is better than\n",
    "mine) in classifying the iris dataset. Still can't not tell if either one is better as the dataset is very small and the testing set\n",
    "is the training set. As the best solution for every problem in the computer sciene field is: \"It depends\"."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
